\chapter[Otimização bio-inspirada]{Otimização bio-inspirada}

Grande parte dos problemas de otimização envolvem encontrar a melhor opção num conjunto de possibilidades que cresce de maneira exponencial. Tais problemas são impossíveis de se resolver em tempo viável e necessitam de estratégias inteligentes para se aproximarem da solução ótima em tempo hábil. Dentre essas estratégias destacam-se os algoritmos gulosos [] e os algoritmos de busca bio-inspirados [].

Os algoritmos gulosos são algoritmos relativamente simples que, apesar de nem sempre obterem a solução ótima, normalmente aproximam-se bem dela [14]. Tais métodos são geralmente utilizados quando apenas um critério é envolvido na otimização, quando mais de um objetivo deve ser analisado, o problema se torna bem mais complexo e essa abordagem deixa de ser indicada.

A otimização bio-inspirada lança mão de estratégias baseadas na natureza para se encontrar boas soluções de forma eficiente. Assim como os algoritmos gulosos, não é possível garantir que se encontre exatamente a solução ótima, mas com uma boa modelagem do problema, é possível encontrar soluções suficientemente próximas. Na natureza, o processo de encontrar uma melhor solução aparece a todo momento, desde a forma como os primeiros animais surgiram, até a maneira como uma simples formiga encontra o caminho mais curto entre a colônia e uma fonte de comida. Ao observar processos comuns da natureza, estudiosos encontraram maneiras simples e eficientes de se resolver diversos problemas de otimização matemática [].

Os principais métodos bio-inspirados na literatura de otimização matemática são os algoritmos genéticos (AG), as colônias de formigas (ACO) e os enxames de partículas (PSO). Os algoritmos genéticos se inspiram na teoria da evolução de Darwin. Segundo [], cada indivíduo possui um material genético que é cruzado com os genes de outro representante da espécie para gerar um novo indivíduo, durante tal cruzamento ainda podem ocorrer mutações aleatórias que podem tanto gerar características benéficas quanto maléficas. O ambiente determina a parte da população que sobrevive e a parte que perece. Os indivíduos sobreviventes, ou seja, aqueles bem adaptados ao ambiente, possuem maiores chances de se reproduzir e espalhar suas boas características genéticas. Desta forma, o processo de evolução das espécies nada mais faz do que gerar indivíduos e selecionar os melhores, repetindo o processo até que se obtenha indivíduos bem adaptados ao ambiente em questão. 

Os ACOs são inspirados no comportamento das formigas, organismos simples que quando analisados em conjunto (colônia) apresentam comportamento complexo. O interesse nas formigas vem da observação de que ao buscarem por comida, acabam por encontrar o caminho mais rápido entre a fonte de alimento e o formigueiro. Como podem seres tão simples resolverem eficientemente um problema de otimização? Estudos revelaram que as formigas se baseiam no depósito de feromônios para se guiarem, quanto mais forte o feromônio em um caminho, maior a chance do mesmo ser tomado. Tal comportamento serviu de inspiração para os algoritmos de otimização bio-inspirados, dando origem ao ACO. Os PSOs, assim como os ACOs são inspirados no comportamento emergente de populações de animais simples. A otimização por enxame de partículas se inspira na navegação de pássaros, onde cada elemento da formação se guia através dos pássaros à frente. O algorítimo se baseia na direção e velocidade de cada elemento do enxame, determinando a exploração do espaço de busca através de operações vetoriais, portanto é uma estratégia indicada para problemas contínuos, que não é o caso dos problemas explorados nesta dissertação.

Em geral, todo algoritmo de otimização bio-inspirado inicia sua busca através da geração de soluções aleatórias e então entra em um laço, onde as melhores soluções guiam a construção de novas soluções que serão submetidas ao mesmo processo até que uma condição de parada seja atingida. Como não é necessário gerar todas as soluções possíveis, são métodos eficazes que, quando bem modelados, encontram um conjunto de boas soluções que resolvem o problema. Uma das principais diferenças entre os algoritmos bio-inspirados e as demais estratégias de otimização é o fato de que os primeiros produzem um conjunto de soluções aproximadas, o que oferece ao usuário uma gama de boas solução para que possa ele mesmo decidir qual utilizar.

\section{Algoritmos Genéticos (AGs)}
Os algoritmos genéticos são métodos de busca baseados na teoria da evolução de Charles Darwin [6]. A teoria de Darwin, hoje já endossada por diversas observações no campo da biologia, parte do princípio de que os organismos se adaptam ao ambiente em que vivem através de mutação, cruzamento e seleção natural. De maneira aleatória, um indivíduo em uma população pode ter alguma característica alterada, esse novo atributo pode ajudá-lo a sobreviver em seu habitat ou atrapalhá-lo. Os indivíduos com mutações favoráveis têm maiores chances de sobreviver e reproduzir, passando suas características benéficas para a geração seguinte. Dessa forma, ao longo de milhões de anos, organismos simples se tornam complexos e extremamente adaptados ao meio.

A ideia dos algoritmos genéticos é aplicar o mesmo conceito da evolução natural na computação, a ideia é partir de soluções aleatórias e após várias iterações de mutação, cruzamento (ou \textit{crossover}) e seleção encontrar um conjunto de soluções que resolvem bem o problema. Nesta ideia, o indivíduo na população representa uma solução, o meio representa o problema e as operações de mutação e cruzamento devem ser definidas, respectivamente, de forma a permitir uma alteração aleatória em uma solução e a combinação de duas soluções.

Em um algoritmo genético, primeiramente gera-se uma população inicial com indivíduos aleatórios e calcula-se a aptidão de cada um. No caso de um problema de otimização para uma função objetivo $f$, a aptidão de um indivíduo $x$ é dada por $f(x)$. Após esse processo de inicialização parte-se para a execução do laço do AG que consiste em:

\begin{enumerate}  
	\item Sortear os pares de pais; 
	\item Aplicar o cruzamento em cada par e gerar os filhos; 
	\item Aplicar a mutação aos filhos de acordo com uma taxa de mutação pré-estabelecida;
	\item Avaliar os filhos;
	\item Selecionar os melhores entre pais e filhos para formar a população da iteração seguinte (elitismo).
\end{enumerate}

O laço do AG termina quando uma condição de término estabelecida pelo usuário é atingida, e.g., 100 iterações.

\subsection{Representação do indivíduo}
A principal dificuldade ao se elaborar um algoritmo genético é definir a representação do indivíduo. O indivíduo representa uma possível solução para o problema e deve ser codificado em uma estrutura que permita a mutação e a troca de características com outro indivíduo (cruzamento). Na proposição original do AG [], o indivíduo é representado de forma binária, ou seja, a solução para o problema é codificada em bits, que podem facilmente ser invertidos (mutação) ou copiados de um elemento para outro (cruzamento).

No problema da mochila 0/1, por exemplo, existe um conjunto de itens $I$ com pesos e valores e uma mochila com capacidade limitada. Deve-se descobrir qual a melhor forma de se arranjar os itens de maneira que a soma dos valores de cada um seja máxima e que a capacidade da mochila não seja excedida. Para representar uma solução deste problema em um AG, basta assumir um vetor binário de tamanho igual a $|I|$, onde diz-se que o item está na mochila se sua posição correspondente no vetor binário é 1 e não está, caso contrário.

Outras representações de indivíduos que não binárias também são possíveis, mas apresentam novos desafios. Em problemas de menores caminhos, por exemplo, normalmente trabalha-se com grafos. Logo, um indivíduo é um grafo e tanto a mutação quanto o cruzamento deverão ser operações em grafos.

para elaborar a representação do indivíduo no AG, deve-se levar em consideração a facilidade de manipulação da estrutura, a possibilidade de se introduzir um fator aleatório (mutação) e, principalmente, a representação das características de ambos os pais nos filhos, se a estrutura não permite a herança de características, não é uma boa escolha para se utilizar num algoritmo genético. Além disso, é preciso se certificar que cada solução pode ser representada de uma única maneira e que cada indivíduo pode representar uma única solução (relação um-para-um).

\subsection{Operadores Genéticos}
Nos algoritmos genéticos destacam-se três operações principais: cruzamento, mutação e seleção. O cruzamento e a mutação estão diretamente ligados com a escolha da representação do indivíduo, enquanto a seleção opera sobre a avaliação (\textit{fitness}) de cada elemento da população.

Num algoritmo genético, cada iteração do laço principal é chamada de de geração. No início de cada geração, sorteia-se pares de pais de acordo com suas aptidões para que seja gerada uma nova população de filhos. Cada par é composto de duas cadeias genéticas, uma correspondente a cada indivíduo do par. Para gerar o filho, cruza-se os dois materiais a fim de se obter uma nova solução que compartilhe características de ambos genitores. Esse processo é conhecido como cruzamento, ou \textit{crossover}. Existem várias maneira de se cruzar cadeias genéticas, a escolha depende principalmente da estrutura de dados usada para representar um indivíduo. A estrutura mais comum e proposta no artigo original de Goldberg [] é a cadeia binária, onde uma solução é codificada em bits. Dispondo de uma sequência de bits, a forma mais trivial de se efetuar o cruzamento é gerando um novo $array$ onde a primeira metade dos bits pertence a um pai e a segunda pertence a outro. Existem diversas formas de se combinar duas cadeias de bits, dentre elas podem-se destacar:

\begin{itemize}  
	\item Ponto de cruzamento único: uma posição $i$ de uma das cadeias é sorteada. O filho herda os $i$ primeiros genes do pai 1 e restante do pai 2.
	\item Dois pontos de cruzamento: ao invés de se utilizar apenas um ponto para dividir o material genético, este método divide a cadeia binária em três partes. O filho herda a primeira parte do pai 1, a segunda parte do pai 2 e a terceira novamente do pai 1.
	\item Cruzamento uniforme: cada bit do filho é obtido de forma aleatória, pode vir tanto do pai 1 quanto do pai 2. Em termos de implementação, sorteia-se uma máscara binária e para cada bit 0 da máscara, copia-se o bit na mesma posição do pai 1 para o filho. Para cada bit 1, copia-se o bit do pai 2.
	\item Cruzamento aritmético: realiza-se uma operação binária entre a cadeia do pai 1 e do pai 2, e.g. AND, OR, XOR, etc.
\end{itemize}

Após gerar os materiais genéticos de cada filho, é preciso permitir que ocorra uma mutação, ou seja, uma mudança aleatória no material genético. A chance de uma mutação ocorrer depende de um parâmetro do AG chamado de ``taxa de mutação''. O processo de alteração genética aleatória em uma cadeia binária é simples, basta sortear um bit e invertê-lo.

O cruzamento normalmente gera um ou dois filhos para cada pai. Em todos os métodos descritos anteriormente é possível obter um segundo filho com o material genético não utilizado. Independente do número de filhos, o fato é que, após o processo de \textit{crossover}, a população será maior que seu limite máximo e por essa razão deve-se eliminar parte dela. A seleção natural sem elitismo, simplesmente elimina a população mais velha (pais). A seleção natural com elitismo é normalmente mais interessante, pois permite a sobrevivência dos indivíduos mais aptos considerando a totalidade da população, sendo assim, avalia-se todos os pais e filhos e mantém-se aqueles com melhor aptidão. A aptidão de cada indivíduo é dada por seu desempenho relativo à função de otimização.

\section{Colônia de formigas (ACO)}
A otimização por colônia de formigas (ACO), proposto em [], é um modelo de busca bio-inspirado que parte da ideia de que estruturas simples, com alguma espécie de comunicação, podem gerar um comportamento complexo quando colocadas em conjunto. A inspiração do ACO é o forrageamento em uma colônia de formigas. Na natureza, observa-se que as formigas, mesmo sendo seres vivos simples, conseguem encontrar o melhor caminho entre o formigueiro e a fonte de comida. A partir do estudo desse comportamento, descobriu-se que tal faceta é possível através de uma comunicação indireta entre os animais. Ao fazer um caminho, as formigas depositam uma substância chamada feromônio, a qual pode ser sentida por outros membros da espécie. Uma formiga ao decidir qual caminho percorrer, tem maior chance de escolher aquele com a maior quantidade de feromônios. Além disso, a substância evapora com o tempo. Dessa forma, quanto menor o caminho, maior a frequência com a qual as formigas depositarão feromônio e, portanto, maior será a chance de ser escolhido, criando um ciclo vicioso.

Ao trazer o conceito de colônia de formigas para a computação, observa-se um grande potencial para se resolver problemas em grafo. Por exemplo, para descobrir o caminho de um vértice $A$ a um vértice $B$ que visita o menor número de vértices em um grafo $G$ sem pesos, bastaria simular várias formigas que partem de $A$ e chegam em $B$ fazendo um caminho baseado na quantidade de feromônios em cada aresta. Ao final de cada iteração, atualiza-se o valor do feromônio em cada aresta de acordo com a evaporação e com as arestas que foram de fato escolhidas pelas formigas. Dessa forma, espera-se que, após várias iterações, a quantidade de feromônios seja suficiente para guiar uma formiga pelo melhor caminho entre $A$ e $B$.

O primeiro passo de um ACO é inicializar as arestas do grafo com quantidade zero de feromônios. O passo seguinte é o laço principal, onde a cada iteração, cada formiga na colônia percorre o caminho do vértice de partida (formigueiro) ao nó destino (fonte de comida). Dependendo da formulação do problema, o caminho de volta também pode ser realizado. Ao final de cada iteração atualiza-se os feromônios em cada aresta. O laço termina quando uma condição de parada pré-determinada é atingida, normalmente um número máximo de iterações.

\subsection{Representação da solução}
No ACO, a solução é representada pelo caminho feito pela formiga no grafo, normalmente uma lista de vértices, uma árvore ou um subgrafo do grafo de entrada. No caso onde o problema consiste em encontrar o menor caminho, a solução pode ser uma lista de vértices. Caso seja necessário encontrar caminhos entre a raiz e diversos destinos, pode-se representar a solução como uma árvore. Nem sempre é claro decidir a codificação da solução, no problema da mochila, por exemplo, não é trivial a visualização de um grafo no processo da construção da solução.

\subsection{Construção da solução}
Independente da representação escolhida, deve ser possível relacionar cada partícula da solução com uma quantidade de feromônios na estrutura principal. Por exemplo, no caso de grafos, as arestas escolhidas para montar a solução devem ter seus feromônios incrementados a fim de guiar a próxima geração de formigas. Em cada época (iteração do laço principal) constrói-se um número pré-determinado de soluções, onde cada formiga, a partir dos valores de feromônios, decide as partículas que vão compor sua solução. De forma geral, dado um grafo $G$ e um nó inicial, o processo de construção da solução sempre verifica todos os movimentos possíveis para a formiga, tomando sua decisão de acordo com os feromônios e as heurísticas de cada uma das possibilidades. 

Além dos feromônios, as formigas ainda utilizam as informações de heurística para decidir o próximo passo. Uma heurística é uma função que estima a qualidade do caminho e normalmente representa o peso de uma aresta. Estando em um vértice $i$ de um grafo $G$, uma formiga tem probabilidade $p(i,j)$ de escolher a aresta que leva ao vértice vizinho $j$.

\[ p(i,j) = \frac{\tau_{i,j}^\alpha * \eta_{i,j}^\beta}{\sum_{v \in vizinhança(i)} \tau_{i,v}^\alpha * \eta_{i,v}^\beta} \]

Onde:

\begin{itemize}  
	\item $\tau_{i,j}^\alpha$: feromônio na aresta $(i,j)$ elevado à constante pré-determinada $\alpha$. $\alpha$ representa a importância que deve ser dada ao valor do feromônio.
	\item $\eta_{i,j}^\beta$: heurística da aresta $(i,j)$ elevada à constante pré-determinada $\beta$. $\beta$ representa a importância que deve ser dada à heurística. A heurística de uma aresta é dada em função do peso, normalmente $1/peso$ em problemas de minimização.
	\item $vizinhança(i)$: todo vértice em $G$ para o qual é possível construir um caminho para $i$ com apenas uma aresta.
\end{itemize}

\subsection{Atualização dos feromônios}
Existem duas ocasiões onde o feromônio das arestas pode ser atualizado: no momento em que a formiga passa pela aresta e no fim de cada iteração. A maioria das implementações considera apenas o segundo caso, pois assim é possível que se avalie as soluções e que se incremente os feromônios de acordo com os desempenhos. Ao fim de cada época, utiliza-se a seguinte fórmula para se atualizar a estrutura de feromônios $\tau$:

\[ \tau_{i,j} = (1 - \rho) * \tau_{i,j} + \sum_{k \in formigas} \Delta\tau_{i,j}(k)\]

Onde:

\begin{itemize}  
	\item $\rho$: coeficiente de evaporação. Determina o quão rápido o feromônio deve desaparecer das arestas após depositado.
	\item $formigas$: conjunto de todas as formigas na iteração.
	\item $\Delta\tau_{i,j}(k)$: quantidade de feromônio depositada pela formiga $k$ na aresta $i,j$.
\end{itemize}

A quantidade de feromônio depositada por uma formiga $k$ em uma aresta $i,j$ é dada por:

\[ \Delta\tau_{i,j}(k) = \begin{cases} \frac{Q}{L_k},& \text{if } x\geq 1\\ 0,& \text{caso contrário} \end{cases} \]

Onde:

\begin{itemize}  
	\item $Q$: Quantidade máxima de feromônio que pode ser depositada por uma formiga.
	\item $L_k$: Custo da solução gerada pela formiga  $k$.
\end{itemize}

O ACO é normalmente utilizado para encontrar o menor caminho ou árvore de menor custo em um grafo. A esperança é que após várias gerações, as formigas percorram sempre o melhor caminho possível.


